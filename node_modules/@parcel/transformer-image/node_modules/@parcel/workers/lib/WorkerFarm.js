"use strict";

Object.defineProperty(exports, "__esModule", {
  value: true
});
Object.defineProperty(exports, "Handle", {
  enumerable: true,
  get: function () {
    return _Handle.default;
  }
});
exports.default = void 0;

function _assert() {
  const data = _interopRequireDefault(require("assert"));

  _assert = function () {
    return data;
  };

  return data;
}

function _nullthrows() {
  const data = _interopRequireDefault(require("nullthrows"));

  _nullthrows = function () {
    return data;
  };

  return data;
}

function _events() {
  const data = _interopRequireDefault(require("events"));

  _events = function () {
    return data;
  };

  return data;
}

function _core() {
  const data = require("@parcel/core");

  _core = function () {
    return data;
  };

  return data;
}

function _diagnostic() {
  const data = _interopRequireWildcard(require("@parcel/diagnostic"));

  _diagnostic = function () {
    return data;
  };

  return data;
}

var _Worker = _interopRequireDefault(require("./Worker"));

var _cpuCount = _interopRequireDefault(require("./cpuCount"));

var _Handle = _interopRequireDefault(require("./Handle"));

var _childState = require("./childState");

var _backend = require("./backend");

var _Profiler = _interopRequireDefault(require("./Profiler"));

var _Trace = _interopRequireDefault(require("./Trace"));

function _fs() {
  const data = _interopRequireDefault(require("fs"));

  _fs = function () {
    return data;
  };

  return data;
}

function _logger() {
  const data = _interopRequireDefault(require("@parcel/logger"));

  _logger = function () {
    return data;
  };

  return data;
}

function _getRequireWildcardCache(nodeInterop) { if (typeof WeakMap !== "function") return null; var cacheBabelInterop = new WeakMap(); var cacheNodeInterop = new WeakMap(); return (_getRequireWildcardCache = function (nodeInterop) { return nodeInterop ? cacheNodeInterop : cacheBabelInterop; })(nodeInterop); }

function _interopRequireWildcard(obj, nodeInterop) { if (!nodeInterop && obj && obj.__esModule) { return obj; } if (obj === null || typeof obj !== "object" && typeof obj !== "function") { return { default: obj }; } var cache = _getRequireWildcardCache(nodeInterop); if (cache && cache.has(obj)) { return cache.get(obj); } var newObj = {}; var hasPropertyDescriptor = Object.defineProperty && Object.getOwnPropertyDescriptor; for (var key in obj) { if (key !== "default" && Object.prototype.hasOwnProperty.call(obj, key)) { var desc = hasPropertyDescriptor ? Object.getOwnPropertyDescriptor(obj, key) : null; if (desc && (desc.get || desc.set)) { Object.defineProperty(newObj, key, desc); } else { newObj[key] = obj[key]; } } } newObj.default = obj; if (cache) { cache.set(obj, newObj); } return newObj; }

function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }

let referenceId = 1;

/**
 * workerPath should always be defined inside farmOptions
 */
class WorkerFarm extends _events().default {
  callQueue = [];
  ending = false;
  warmWorkers = 0;
  workers = new Map();
  handles = new Map();
  sharedReferences = new Map();
  sharedReferencesByValue = new Map();
  serializedSharedReferences = new Map();

  constructor(farmOptions = {}) {
    super();
    this.options = {
      maxConcurrentWorkers: WorkerFarm.getNumWorkers(),
      maxConcurrentCallsPerWorker: WorkerFarm.getConcurrentCallsPerWorker(),
      forcedKillTime: 500,
      warmWorkers: false,
      useLocalWorker: true,
      // TODO: setting this to false makes some tests fail, figure out why
      backend: (0, _backend.detectBackend)(),
      ...farmOptions
    };

    if (!this.options.workerPath) {
      throw new Error('Please provide a worker path!');
    } // $FlowFixMe this must be dynamic


    this.localWorker = require(this.options.workerPath);
    this.localWorkerInit = this.localWorker.childInit != null ? this.localWorker.childInit() : null;
    this.run = this.createHandle('run'); // Worker thread stdout is by default piped into the process stdout, if there are enough worker
    // threads to exceed the default listener limit, then anything else piping into stdout will trigger
    // the `MaxListenersExceededWarning`, so we should ensure the max listeners is at least equal to the
    // number of workers + 1 for the main thread.
    //
    // Note this can't be fixed easily where other things pipe into stdout -  even after starting > 10 worker
    // threads `process.stdout.getMaxListeners()` will still return 10, however adding another pipe into `stdout`
    // will give the warning with `<worker count + 1>` as the number of listeners.

    process.stdout.setMaxListeners(Math.max(process.stdout.getMaxListeners(), WorkerFarm.getNumWorkers() + 1));
    this.startMaxWorkers();
  }

  workerApi = {
    callMaster: async (request, awaitResponse = true) => {
      // $FlowFixMe
      let result = await this.processRequest({ ...request,
        awaitResponse
      });
      return (0, _core().deserialize)((0, _core().serialize)(result));
    },
    createReverseHandle: fn => this.createReverseHandle(fn),
    callChild: (childId, request) => new Promise((resolve, reject) => {
      (0, _nullthrows().default)(this.workers.get(childId)).call({ ...request,
        resolve,
        reject,
        retries: 0
      });
    }),
    runHandle: (handle, args) => this.workerApi.callChild((0, _nullthrows().default)(handle.childId), {
      handle: handle.id,
      args
    }),
    getSharedReference: ref => this.sharedReferences.get(ref),
    resolveSharedReference: value => this.sharedReferencesByValue.get(value)
  };

  warmupWorker(method, args) {
    // Workers are already stopping
    if (this.ending) {
      return;
    } // Workers are not warmed up yet.
    // Send the job to a remote worker in the background,
    // but use the result from the local worker - it will be faster.


    let promise = this.addCall(method, [...args, true]);

    if (promise) {
      promise.then(() => {
        this.warmWorkers++;

        if (this.warmWorkers >= this.workers.size) {
          this.emit('warmedup');
        }
      }).catch(() => {});
    }
  }

  shouldStartRemoteWorkers() {
    return this.options.maxConcurrentWorkers > 0 || !this.options.useLocalWorker;
  }

  createHandle(method, useMainThread = false) {
    return async (...args) => {
      // Child process workers are slow to start (~600ms).
      // While we're waiting, just run on the main thread.
      // This significantly speeds up startup time.
      if (this.shouldUseRemoteWorkers() && !useMainThread) {
        return this.addCall(method, [...args, false]);
      } else {
        if (this.options.warmWorkers && this.shouldStartRemoteWorkers()) {
          this.warmupWorker(method, args);
        }

        let processedArgs;

        if (!useMainThread) {
          processedArgs = (0, _core().restoreDeserializedObject)((0, _core().prepareForSerialization)([...args, false]));
        } else {
          processedArgs = args;
        }

        if (this.localWorkerInit != null) {
          await this.localWorkerInit;
          this.localWorkerInit = null;
        }

        return this.localWorker[method](this.workerApi, ...processedArgs);
      }
    };
  }

  onError(error, worker) {
    // Handle ipc errors
    if (error.code === 'ERR_IPC_CHANNEL_CLOSED') {
      return this.stopWorker(worker);
    } else {
      _logger().default.error(error, '@parcel/workers');
    }
  }

  startChild() {
    let worker = new _Worker.default({
      forcedKillTime: this.options.forcedKillTime,
      backend: this.options.backend,
      shouldPatchConsole: this.options.shouldPatchConsole,
      sharedReferences: this.sharedReferences
    });
    worker.fork((0, _nullthrows().default)(this.options.workerPath));
    worker.on('request', data => this.processRequest(data, worker));
    worker.on('ready', () => this.processQueue());
    worker.on('response', () => this.processQueue());
    worker.on('error', err => this.onError(err, worker));
    worker.once('exit', () => this.stopWorker(worker));
    this.workers.set(worker.id, worker);
  }

  async stopWorker(worker) {
    if (!worker.stopped) {
      this.workers.delete(worker.id);
      worker.isStopping = true;

      if (worker.calls.size) {
        for (let call of worker.calls.values()) {
          call.retries++;
          this.callQueue.unshift(call);
        }
      }

      worker.calls.clear();
      await worker.stop(); // Process any requests that failed and start a new worker

      this.processQueue();
    }
  }

  processQueue() {
    if (this.ending || !this.callQueue.length) return;

    if (this.workers.size < this.options.maxConcurrentWorkers) {
      this.startChild();
    }

    let workers = [...this.workers.values()].sort((a, b) => a.calls.size - b.calls.size);

    for (let worker of workers) {
      if (!this.